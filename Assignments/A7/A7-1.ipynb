{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Explainable Machine Learing (Part 1)\n",
    "\n",
    "## Objective:\n",
    "\n",
    "Interpreting how a machine learning model works is crucial from many aspects, such as debugging the model, improving the model, and derive new insights from the model. There are many model explanation techniques that we can use for interpreting a black box model itself or its predictions. Also, some models are transparent that we can directly get insights from its structure or learned parameters. In this assignment, you are going to train different models on a dataset and try different approaches to explain the model and get some insights. After completing this assignment, you should be able to answer the following questions:\n",
    "\n",
    "1. How to explain transparent models?\n",
    "2. How to implement the permutation method to explain black-box models?\n",
    "3. How to create and interpret partial dependence plots?\n",
    "4. How to implement the global surrogate method to explain black-box models?\n",
    "5. How to use SHAP to explain model predictions and interpret its explanation results? \n",
    "6. How to use LIME to explain model predictions and  interpret its explanation results? \n",
    "\n",
    "The data can be downloaded from [A7-1-data.zip](A7-1-data.zip)\n",
    "\n",
    "\n",
    "\n",
    "## 0. Preparation\n",
    "\n",
    "Import relevant libraries and load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataprep.eda import plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use is a binary forest covertype dataset and we will predict the forest cover type from cartographic variables only. The first ten features are numerical features, there are also two categorical features in a one-hot encoding fashion (4 and 40 vector length each), the last column is the target forest cover type (binary). More details about the dataset can be found at [https://archive.ics.uci.edu/ml/datasets/covertype](https://archive.ics.uci.edu/ml/datasets/covertype). Please make sure you understand the meaning of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and take a look at data distribution\n",
    "data = pd.read_csv('bforest_sample.csv', delimiter=',')\n",
    "plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test dataset with respect to ratio 0.8:0.2\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=733)\n",
    "X_train, y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "X_test, y_test = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "feature_names = list(X_train)\n",
    "\n",
    "# rescale\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(data=scaler.fit_transform(X_train), columns=feature_names)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Transparent Model\n",
    "\n",
    "In this task, you are going to train a logistic regression model and interpret it. For logistic regression, since the effect of each feature is simply added together, we can interpret it directly by looking at the coefficient of each feature. Please follow the comment to finish the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model\n",
    "lr = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default figure size\n",
    "plt.rcParams['figure.figsize'] = [16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the coefficient value for each feature by a bar chart\n",
    "def explain_logistic_regression(lr, feature_names):\n",
    "    # --- Write your code below ---\n",
    "\n",
    "# explain the model\n",
    "explain_logistic_regression(lr, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a specific prediction, we can get a more concrete effect of each feature by the product of the coefficient and input feature value. Please follow the comment to finish the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show the effect from each input feature by a bar chart\n",
    "def explain_logistic_regression_prediction(lr, feature_names, sample):\n",
    "    # --- Write your code below ---\n",
    "    \n",
    "explain_logistic_regression_prediction(lr, feature_names, (X_test.iloc[0, :], y_test.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you get from the above plots? Please write down two findings:\n",
    "\n",
    "**Findings:**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]\n",
    "\n",
    "## Task 2. Post-hoc Explanation (Global Model)\n",
    "\n",
    "In this task, you are going to build a gradient boosting tree model and a neural network, and use some techniques we introduced in class to interpret these models. First, let's train the models using training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a gradient boosting classifier\n",
    "gb = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a multi-layer perceptron classifier\n",
    "mlp = MLPClassifier(learning_rate_init=0.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance score (E' - E) for each feature by permutation, use log_loss as error\n",
    "def permutation_importance(model, feature_names, X, y):\n",
    "    # calculate importance score for each feature by purmutation approach\n",
    "    # --- Write your code below ---\n",
    "        \n",
    "    # show the top 5 most important features\n",
    "    # --- Write your code below ---\n",
    "    \n",
    "permutation_importance(gb, feature_names, X_test.to_numpy(), y_test.to_numpy())\n",
    "permutation_importance(mlp, feature_names, X_test.to_numpy(), y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Partial dependence plots\n",
    "\n",
    "In this section, you are going to use the [plot_partial_dependence](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html#sklearn.inspection.plot_partial_dependence) provided by sklearn to see the marginal effect of each single numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot partial dependence for numerical features (first 10 features) for gradient boosting classifier\n",
    "# --- Write your code below ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot partial dependence for numerical features (first 10 features) for neural network\n",
    "# --- Write your code below ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Global Surrogate\n",
    "\n",
    "Now, let's train a simple logistic regression based on the gradient boosting tree model and neural network we built before. And use the method we implemented previously to interpret the derived transparent model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train a logistic regression model on gb and mlp and explain using explain_logistic_regression()\n",
    "\n",
    "# --- Write your code below ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Post-hoc Explanation (Single Prediction)\n",
    "\n",
    "### 3.1 Attribution\n",
    "\n",
    "From now, let's focus on interpreting single predictions. [SHAP](https://github.com/slundberg/shap) is an efficient method to approximatly calculate the shapely value we mentioned in class. Please install the library and take a look at the doc. Explain the first prediction made by the gradient boosting tree model in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# use Tree SHAP explainer to explain the gradient boosting tree model\n",
    "# you only need to explain and plot the first explaination\n",
    "# --- Write your code below ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you get from the above representation? Please write down two findings:\n",
    "\n",
    "**Findings:**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]\n",
    "\n",
    "### 3.2 LIME\n",
    "\n",
    "[LIME](https://github.com/marcotcr/lime) is a library implemented by the authors of the paper. Please install the library and take a look at the doc and tutorial. Use it to explain the first prediction made by the neural network model in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "\n",
    "# use LimeTabularExplainer to explain the neural network model\n",
    "# you only need to explain and plot the first explaination\n",
    "# --- Write your code below ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run LIME multiple times, (Q1) what do you think of the stability of LIME? (Q2) Can you briefly explain the reason?\n",
    "\n",
    "**Your Answer:** \n",
    "1. [ADD TEXT] \n",
    "2. [ADD TEXT] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
